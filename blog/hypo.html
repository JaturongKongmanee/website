<h1>labeling_game</h1>
<ul>
<li><a href="https://chi2024.acm.org/for-authors/papers/">CHI conference on Human Factors in Computing Systems</a> is what we are targeting for.</li>
</ul>
<h2>TO-DOs</h2>
<p><strong>Please note that it does not have to sum up all the work in a giant PR. Please feel free to scope it down and create a PR based on each piece of work so it is easy to review, isolate the implementation, and no stall branches. Delete a branch once completed.</strong></p>
<h2>Phase 1 to-do list according to designated requirements for our pilot study. We expect to get this PR1 done by May. We will need to collect data for modeling and determining game parameters, such as scores, time session:</h2>
<ul>
<li>[ ] @Smiile please update the UX(s) so that @Tiffany can use them to guide a development. — It's under the branch <a href="https://github.com/JaturongKongmanee/labeling_game/tree/sm/design-detail/design">sm/design-detail</a>.</li>
<li>[ ] @Tiffany We should make each card expandable. </li>
<li>[ ] By default all five cards are displayed together on a page (~1200px of height of 13" laptop).</li>
<li>[ ] The maximum height of expanded cards should be about 500px (and if the content requires more than 500px, we will make use of the CSS overflow property to allow for scrolling); thus, only two expanded cards should be displayed on the page.</li>
<li>[ ] A checkbox displays a player word importance (using TF-IDF or its variant BM25 over all documents/cards. Reference is here https://github.com/spencermountain/compromise and https://dev.to/charlesdlandau/natural-language-processing-in-the-browser-52hj). <s>I will finalize with Prof. Mark which one is more helpful and appropriate. And I think, for the sake of simplicity and making our life easier, we better pre-compute TF-IDF using Python and add it to each card as an associated attribute (i.e., a list of important and tf-idf scores).</s> I implemented a script that modifies cards (textual data) by inserting HTML tags along with color code according to the tf-idf scores.</li>
<li>[ ] Use percentage agreement will be used as a score (as of now), that is, <code>the number of ranked cards in agreement/the total number of cards (i.e., 5) x 100</code>. For example, let's say 3 cards matched, we will have <code>3/5 x 100</code> = <code>60</code> points. And they will receive an extra <code>50</code> bonus points based on the following condition: (1) if they finish the ranking task faster than <code>250</code> seconds (300 seconds for the total time) <strong>AND</strong> (2) receive a minimum of <code>60</code> points (i.e., a minimum of three ranked cards in agreement) from the card percentage agreement. Let's use these simple rules for now (I am open to any ideas you may have). Once we have collected data we will have a better idea for determining these game elements. We can run Monte Carlo simulation/approximation as well.</li>
<li>[ ] To say one is better than another one, we need at least (1) a baseline and (2) a proposed method, and statistical methods to show if there exists effects that are statisitcally significant enough to accept that, on average, our proposed method is more effective. In our case, to show our labeling game (proposed method) provides benefit over the traditional labeling (baseline), we will have to implement a baseline where we can just simply show five cards and let players label each card. More fully, each card will have, for example, a checkbox asking if this card is positive, or we could have three checkbox asking positive, negative, and undecided.</li>
<li>[ ] @Tiffany Could you let me know where should I put functions for calculating scores? In other words, where you plan to implement <code>percentage agreement</code>? I will work on other score calculation, that is, <code>Kendall's Cofficient, Weighted Cohen's kappa, Krippendorff's alpha</code>.</li>
<li>[ ] A text box to collect a player's relevant judgment justification</li>
<li>
<p>[ ] @Smiile Instruction of the labeling game should (need to actually) be precise, and that we should say thing like, for example please rank cards based on (or with respect to) XXX criteria: (1), (2), and ... </p>
</li>
<li>
<p><strong>Note</strong>  @smiile I think you can help Tiffany on Firebase or other databases if she needs any help or some clarification. You are expert!</p>
</li>
<li><strong>Note</strong> @smiile Please help pick the font style, and size(s) for each component. — <a href="https://www.canva.com/design/DAGF6dPxDAo/ZxCvhr9-gmPniV7VjSJ86A/edit?utm_content=DAGF6dPxDAo&amp;utm_campaign=designshare&amp;utm_medium=link2&amp;utm_source=sharebutton">Style guide - WIP</a>, everyone can comment on it!</li>
</ul>
<h2>Phase 2 to-do list for enhanced version, and data analysis for the paper. This Phase 2 is expected to be done by June 15.</h2>
<ul>
<li>[ ] We should add the following:</li>
</ul>
<h2>What is it?</h2>
<h3>TF-IDF</h3>
<p>It is a method used to evaluate the importance of words in a document. There are two components: <strong>TF</strong> (term frequency) and <strong>IDF</strong> (inverse document frequency).</p>
<p><strong>TF(t, d)</strong> is a function of <strong>term/word(t)</strong> and <strong>document(d)</strong>, and is calculated as <code>count of t in d / count of words in d</code></p>
<p><strong>IDF(t, N)</strong> is an inverse function of <code>count of documents that t occurs (df(t))</code> and N (a number of total documents considered), aimed to weight down the frequent terms (e.g., a, an, the, of, that) while emphasizing the importance of the rare words, and is calculated as <code>log(N/(df(t) + 1))</code>.</p>
<p>In essence, TF-IDF is calculated as follows: <code>tf-idf(t, d) = tf(t, d) * log(N/(df(t) + 1))</code> Note here that these are variants of TF-IDF but they do not give significant difference.</p>
<h3>Text Similarity: My Reflection on Text Similarity After Dizziness today</h3>
<p>Before I participated the experiment of Mandeep, a Master student, to help him graduate by having some stats to report, I was pondering about card arragement: how should we present the cards to players so that they could rank cards better (with more calibrated confidence). One simple idea is that if we can measure text similarity, we may just include cards into a set such that the set has the maximum variance. I hypothsized that a set of cards with high variance (i.e., each card in the set is different enough for human to notice its class) should help human contrast cards easier, thereby ranking and labeling cards more accurate. What CS taught me? Well, we just represent these cards as vectors (many ways to transform text into vectors--fancy embedding such as word2vec or doc2vec is one example) and do algebra on them. For example, measure cosine similarity among these vectors, or other kind of dot product, or employing some similarity function using Euclidean distance. Waooow life is easy. Unfortunately it is not.</p>
<p>After (almost not) finishing his experiment, I was super dizzy, wanted to puke, could not walk straight. I sat for almost an hour till I felt better. Luckily I was able to walk home safely (dying at home is better than at the lab, right). While walking home I somehow thought of what I left implemeting before participating his experiment--text similarity. What is similarity?--a simple question I could not really answer. I, however, noticed many of his (Mandeep) participants enjoyed his experiment, but me. Yeah, people are different and that they perceive things differently (e.g., different personality, traits). Hence, there are more than one dimension of text similarity, and summarizing it using a single number (scalar--since I mentioned vector hahaha) is not sufficient. For example, one dimension could be "structure", another could be "style", and "content" is likely to deserve its own dimension. These dimensions are perceived differently by different people (or even by the same person at different time).</p>
<p>The problem of measuring text similarity becomes a challenge when taking human perception into account. Perhaps, this is one of many reason that essay is being used in grad school application, because experts read and (subjectively) judge essays based on what school looking for from candidates (of course some tools are used for screening, but not for the final decision). Alright, let's get back to our game. I think the best way is possibly "back to basic" idea and focus on the basic measure based on frequency. Semantic of words/documents is less to be concerned in our context, because medical or insurance claims should contain only pariticular words used in professional settings. Thus, I will use "Term frequency"--the number of times a particular word appeared in a document--and "Document frequency"--the count of documents containing that word--to calculate the text similarity.</p>
<h3>Dimensional Interpretation using Linear (multiple) Regression--My Thought</h3>
<p>Suppose we have some variable associated with the items which we suspect may have a systematic relationship to position in the configuration. One way we could do is to perform a linear regression using this variable (i.e., a rating scale of 0 - 10 confident when labeling, in our case) as the dependent variable and the coordinates of the configuration (spatial map/representation) as the independent variables. If I wear a hat of statisticians, I would say we are regressing the variable over the coordinates of the configuration. Hahahah in the layman term, it just means that we seek some weighted combination of the coordinates of the configuration which agrees with or explains the variable as well as possible (so that we can use the variable as a dimension). We then use the multple correlation coefficient as a measure of how well this can be done.</p>
<p>In order for a variable (again, a rating scale, in our case), to provide satisfactory interpretation of a dimension, two conditions are necessary: (1) the multiple correlation for the scale must be high (indicating that the scale can be well fitted by the coordinates of the configuration), and (2) the scale must have a high regression weight on that dimension (indicating that the angle between the dimension and the direction of the associated scale is small).</p>
<p>Caution here, when the regressed variable is based on prederence ratings, the use of mean ratings based on an entire group can be misleading. But you know what, we three of us are smart and we know that we better determine seprate vectors of mean ratings for identifiable groups (i.e., five groups of varied skilled players) to get meaningful regression weights.</p>
<h1>Implementation References</h1>
<p>(1) <a href="https://drawsql.app/teams/labeling-game/diagrams/labeling-game">Data Modeling</a><br>
(2) <a href="https://www.canva.com/design/DAGF6dPxDAo/ZxCvhr9-gmPniV7VjSJ86A/edit?utm_content=DAGF6dPxDAo&amp;utm_campaign=designshare&amp;utm_medium=link2&amp;utm_source=sharebutton">Style guide</a></p>
<h1>Interesting Methods</h1>
<p>(1) <a href="https://faculty.washington.edu/wobbrock/pubs/chi-11.06.pdf">The Aligned Rank Transform for Nonparametric Factorial
Analyses Using Only ANOVA Procedures</a><br>
(2) <a href="https://cescup.ulb.be/wp-content/uploads/2015/04/Leys_and_Schumann_nonparametric_interactions.pdf">A nonparametric method to analyze interactions: The adjusted rank transform test</a> </p>